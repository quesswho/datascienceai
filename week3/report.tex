\documentclass[a4paper]{article}

\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{biblatex}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{stmaryrd}
\usepackage[dvipsnames]{xcolor}
\usepackage{listings}
\usepackage{float}
\addbibresource{refs.bib}

\begin{document}

\author{
  Sebastian Miles \\
  \href{mailto:miless@chalmers.se}{miless@chalmers.se}
  \and
  Olle Lapidus \\
  \href{mailto:ollelap@chalmers.se}{ollelap@chalmers.se}
}
\title{DAT565/DIT407 Assignment 3}
\date{2024-09-19}

\maketitle
\section*{Problem 1}
Spam messages usually stand out by using aggressive marketing strategies. These emails will frequently use words such as "free", "win", "urgent", etc. They might also contain suspicious links or inquire about your own personal information. In contrast the ham mails will be conversational and more relevant to the receiver. Easy ham is easy to classify due to the straightforward structure and wording. Hard ham contains words and phrasing that might be classified as spam even though it is ham.\\
We used 50\% of the data as training data. With this training we achieved an accuracy of 95.15\%.

88.07


\section*{Problem 2}
We began with building onto the code from the previous problem. We used the CountVectorizer function from the scikit-learn library. We then used fit\_transform and transform on the train set and test set respectively. Then, we used the BinomialNB function on the transformed train and test set. Thirdly we used the predict function on the 


\section*{Problem 3}

\begin{figure}[H]
  \begin{center}
    
    \caption{}
    \label{scatter2}
  \end{center}
\end{figure}

\printbibliography
\appendix

\section*{Code}
\label{app:excode}

\lstset{
	language=Python,
	basicstyle=\ttfamily,
	commentstyle=\color{OliveGreen},
	keywordstyle=\bfseries\color{Magenta},
	stringstyle=\color{YellowOrange},
	numbers=left,
	frame=tblr,
	breaklines=true,
	postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}
\begin{lstlisting}

\end{lstlisting}

\end{document}
